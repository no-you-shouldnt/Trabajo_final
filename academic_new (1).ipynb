{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78be875a",
   "metadata": {},
   "source": [
    "# Corpus Academic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30461b31",
   "metadata": {},
   "source": [
    "## 1. Lectura de datos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc98573f-6644-4c5a-9a08-66dbbe12e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## abrimos los archivos\n",
    "\n",
    "import glob\n",
    "\n",
    "lista_files = glob.glob('academic/*.txt')\n",
    "corpus = []\n",
    "\n",
    "for file in lista_files:\n",
    "    with open(file, 'r', encoding='utf8') as f:\n",
    "        corpus+=[f.read()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15522d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## número de textos\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04e0950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nf0069: when talking about the French gangster film very often and \\nparadoxically in French one talks about the policier that's the name of the \\ngenre so when you you see the word policier er I-E police which relates to the \\npolice it doesn't necessa\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ea93b",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9dd9bf-b5ef-4505-8c67-ad3b187aea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## librerias\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "from nltk import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2fce56-63cb-495b-aaf8-fa7feae6b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jxver\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20361ab2-6bda-46f4-b9bb-561d725c68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## función para remover () y []\n",
    "\n",
    "def a(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14780019-9aa6-4c52-a49a-c526220df1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## aplicamos la función \"a\" a cada texto del corpus\n",
    "\n",
    "corpus = [a(c) for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0b97ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nf0069: when talking about the French gangster film very often and \\nparadoxically in French one talks about the policier that's the name of the \\ngenre so when you you see the word policier er I-E police which relates to the \\npolice it doesn't necessa\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ae884b-c67b-4443-b710-6b0f085cb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dividimos por salto de linea cada texto\n",
    "\n",
    "corpus = [c.replace('♪','').split('\\n') for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c624d8-96bd-449d-8378-ec716a91a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nf0069: when talking about the French gangster film very often and ',\n",
       " \"paradoxically in French one talks about the policier that's the name of the \",\n",
       " 'genre so when you you see the word policier er I-E police which relates to the ',\n",
       " \"police it doesn't necessarily mean that it's to do with a police film or police \",\n",
       " \"procedure as the you have in the American genres but it's co-, covers all er \"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac550f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## eliminamos strings vacíos (cada texto)\n",
    "\n",
    "corpus = [[sentence.strip() for sentence in c if len(sentence)>0] for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6004d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## volvemos a juntar las oraciones :)\n",
    "\n",
    "sentence_list = [' '.join(c) for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d62326-be95-4b3d-817f-a1bfbe6bc0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nf0069: when talking about the French gangster film very often and paradoxically in French one talks about the policier that's the name of the genre so when you you see the word policier er I-E police which relates to the police it doesn't necessarily mean that it's to do with a police film or police procedure as the you have in the American genres but it's co-, covers all er virtually all the films er to do with crime er pretty much from the nineteen- fifties onwards so er a gangster film and a police film will both be called policier in French and sometimes you'll see the in slang this becomes polar er i'm sorry i hope it's not too awkward if i move er polar is P-O-L-A-R er is yep sf0070: sorry nf0069: okay we're just beginning polar is the slang word for policier so le polar refers to the genre of the police crime gangster movie in French er specifically from the nineteen-fifties late forties fifties onwards and so that i will talk today about a particular genre or subgenre of Frenc\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b513cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokens y types\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for texto in sentence_list:\n",
    "    tokens+=texto.split(' ')\n",
    "\n",
    "tokens = [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e00fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67213, 5898)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## número de tokens y types en el corpus\n",
    "\n",
    "len(tokens),len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85bc9c",
   "metadata": {},
   "source": [
    "## análisis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f2d03",
   "metadata": {},
   "source": [
    "### 1. Nominalizaciones\n",
    "El trabajo aquí es con listas de oraciones. Extraemos los sustantivos :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8870d8c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\jxver\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (3.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (59.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (59.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "248d1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "oraciones_nlp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4563f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## identificamos el lema y el pos\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    doc = nlp(sentence)\n",
    "    sent = [(token.lemma_.lower(),token.pos_) for token in doc]\n",
    "    oraciones_nlp += [sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "131ef0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8732"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oraciones_nlp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1c211ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_tokens_types(oraciones):\n",
    "    number=[pair[0] for pair in oraciones]\n",
    "    return len(number),len(set(number)),len(set(number))/len(number)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31835204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 1162, 13.30737517178195)\n",
      "(8753, 1024, 11.698846109905176)\n",
      "(8768, 1236, 14.096715328467152)\n",
      "(9940, 1149, 11.559356136820925)\n",
      "(13901, 1711, 12.308467016761385)\n",
      "(8239, 1127, 13.678844519966017)\n",
      "(5267, 881, 16.726789443706096)\n",
      "(7535, 945, 12.541473125414731)\n"
     ]
    }
   ],
   "source": [
    "## número de tokens y types para los 8 textos \n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    print(number_tokens_types(oraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41bec5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_nouns(oraciones):\n",
    "    number=[pair for pair in oraciones if pair[1]=='NOUN']\n",
    "    return len(number),len(set(number)),len(set(number))/len(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0661b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1436, 458, 0.318941504178273)\n",
      "(1429, 353, 0.2470258922323303)\n",
      "(1524, 495, 0.3248031496062992)\n",
      "(1564, 441, 0.2819693094629156)\n",
      "(2864, 709, 0.24755586592178772)\n",
      "(1676, 487, 0.2905727923627685)\n",
      "(1100, 304, 0.27636363636363637)\n",
      "(1368, 359, 0.26242690058479534)\n"
     ]
    }
   ],
   "source": [
    "## número de nouns tokens y types para los 8 textos \n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    print(number_nouns(oraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f07108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## la pregunta es: ¿De este número de nouns cuántos son nominalizaciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3894534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reglas de nominalization\n",
    "\n",
    "## reglas de nominalization\n",
    "## puse las palabras lematizadas, en ese caso, solo es necesario poner las palabras en singular\n",
    "\n",
    "no_nom = ['thing', 'things', 'somethings', 'something', 'anything', 'everything', 'nothing','original', 'special', 'normal', 'version', 'tutorial', 'moment', 'criminal', 'tradition', 'morning', 'question', 'element', 'quality']\n",
    "terminacion = ['ment','ments','tions', 'tion','sions', 'sion', 'ibility','ibilities', 'ity','ities', 'ness','nesses', 'al','als','ings', 'ing'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87126c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nominalization(oraciones):\n",
    "    nom = []\n",
    "    for word in oraciones:\n",
    "        if word[0] not in no_nom:\n",
    "            if word[1]=='NOUN':\n",
    "                for END in terminacion:\n",
    "                    if word[0].endswith(END):\n",
    "                        nom+=[word[0]]\n",
    "    return nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "000c1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_list = []\n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    nom_list += [nominalization(oraciones)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b8a6077",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hybridity',\n",
       " 'hybridity',\n",
       " 'sexuality',\n",
       " 'notion',\n",
       " 'translation',\n",
       " 'publishing',\n",
       " 'lettering',\n",
       " 'fiction',\n",
       " 'material',\n",
       " 'relation',\n",
       " 'connection',\n",
       " 'connection',\n",
       " 'marketing',\n",
       " 'revival',\n",
       " 'revival',\n",
       " 'mention',\n",
       " 'movement',\n",
       " 'action',\n",
       " 'action',\n",
       " 'movement',\n",
       " 'consciousness',\n",
       " 'adaptation',\n",
       " 'consciousness',\n",
       " 'consciousness',\n",
       " 'consciousness',\n",
       " 'beginning',\n",
       " 'expression',\n",
       " 'highlighting',\n",
       " 'exception',\n",
       " 'production',\n",
       " 'production',\n",
       " 'production',\n",
       " 'production',\n",
       " 'moral',\n",
       " 'depiction',\n",
       " 'morality',\n",
       " 'relation',\n",
       " 'morality',\n",
       " 'sexuality',\n",
       " 'renewal',\n",
       " 'popularity',\n",
       " 'objection',\n",
       " 'morality',\n",
       " 'objection',\n",
       " 'pity',\n",
       " 'identity',\n",
       " 'location',\n",
       " 'understatement',\n",
       " 'understatement',\n",
       " 'movement',\n",
       " 'depiction',\n",
       " 'activity',\n",
       " 'reaction',\n",
       " 'bonding',\n",
       " 'relation',\n",
       " 'unfolding',\n",
       " 'action',\n",
       " 'conversation',\n",
       " 'action',\n",
       " 'foreignness',\n",
       " 'reality',\n",
       " 'relation',\n",
       " 'resolution',\n",
       " 'identity',\n",
       " 'displacement',\n",
       " 'sounding',\n",
       " 'darkness',\n",
       " 'reversal',\n",
       " 'sounding',\n",
       " 'discussion',\n",
       " 'arrival',\n",
       " 'reading',\n",
       " 'reading',\n",
       " 'popularity',\n",
       " 'reading',\n",
       " 'argument',\n",
       " 'relation',\n",
       " 'displacement',\n",
       " 'occupation',\n",
       " 'reading',\n",
       " 'reading',\n",
       " 'occupation',\n",
       " 'revisiting',\n",
       " 'hankering',\n",
       " 'viewing',\n",
       " 'reading',\n",
       " 'retirement',\n",
       " 'activity',\n",
       " 'position',\n",
       " 'activity',\n",
       " 'reading',\n",
       " 'betrayal',\n",
       " 'betrayal',\n",
       " 'occupation',\n",
       " 'modernity',\n",
       " 'consumption',\n",
       " 'recession',\n",
       " 'modernization',\n",
       " 'beginning',\n",
       " 'community',\n",
       " 'community',\n",
       " 'community',\n",
       " 'community',\n",
       " 'consumption',\n",
       " 'consumption',\n",
       " 'living',\n",
       " 'living',\n",
       " 'modernity',\n",
       " 'professional',\n",
       " 'business',\n",
       " 'business',\n",
       " 'figuration',\n",
       " 'capital',\n",
       " 'renewal',\n",
       " 'mirroring',\n",
       " 'reading',\n",
       " 'figuring',\n",
       " 'hybridization']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ¿Cuántas de estas son realmente nominalizaciones? Por ejemplo, ¿qué ocurre con \"fragment\"? Eso podría mejorarse, o al menos\n",
    "## plantear formas en que podría mirarse de otras formas\n",
    "\n",
    "nom_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9b57f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nom_list = []\n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    num_nom_list += [len(nominalization(oraciones))/number_nouns(oraciones)[0]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75224b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.217270194986073,\n",
       " 17.424772568229532,\n",
       " 15.288713910761153,\n",
       " 12.21227621483376,\n",
       " 16.23603351955307,\n",
       " 20.286396181384248,\n",
       " 28.72727272727273,\n",
       " 25.877192982456144]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## porcentaje de nominalizaciones con respecto al total de tokens sustantivos para cada texto :)\n",
    "\n",
    "num_nom_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9478e52-81de-4f13-a4c8-d0e03f94d326",
   "metadata": {},
   "source": [
    "# 2. Academic Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a4cc185-ef81-49c2-b51e-578b9d7b7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abriendo la lista de palabras academicas\n",
    "with open('AcademicWordList.txt') as f:\n",
    "    AWL=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ee41adc-517e-41be-806c-148c381e9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir por salto de linea\n",
    "AWL= AWL.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63ed4dbe-ed1f-477d-985f-d56ce41209c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##eliminar espacios en blanco\n",
    "AWL = [palabra.split(' ') for palabra in AWL if len(palabra)>0]\n",
    "AWL = [item for sublist in AWL for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4cfc75a-a894-49ce-b5eb-361294357c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWL.remove('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43009065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AWL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "164fe832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nf0069', 'PROPN'),\n",
       " (':', 'PUNCT'),\n",
       " ('when', 'SCONJ'),\n",
       " ('talk', 'VERB'),\n",
       " ('about', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('french', 'ADJ'),\n",
       " ('gangster', 'NOUN'),\n",
       " ('film', 'NOUN'),\n",
       " ('very', 'ADV')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oraciones_nlp[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fd2f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cada texto tiene la forma\n",
    "\n",
    "texto = list(zip(*oraciones_nlp[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea9dd214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nf0069',\n",
       " ':',\n",
       " 'when',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'the',\n",
       " 'french',\n",
       " 'gangster',\n",
       " 'film',\n",
       " 'very')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127d700-4148-4527-8a12-b76c3454da6f",
   "metadata": {},
   "source": [
    "# AQUI ES DONDE TENGO PROBLEMAS, NO ES QUE HAYA ERROR PERO ME TOMA TODO COMO UN SOLO TEXTO Y NO COMO TEXTOS SEPARADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6543a8d-85a8-458e-9940-7dbadd3f14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def academic(tokens):\n",
    "    aca_list=[]\n",
    "    for word in tokens:\n",
    "        if word in AWL:\n",
    "            aca_list+=[word]\n",
    "    return aca_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b36804aa-7fc4-4b24-bb26-c48170f8d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aca_words_per_text = []\n",
    "\n",
    "for oracion in oraciones_nlp:\n",
    "    texto = list(zip(*oracion))[0]\n",
    "    aca_words = academic(texto)\n",
    "    aca_words_per_text+=[aca_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67d763db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theme',\n",
       " 'lecture',\n",
       " 'lecture',\n",
       " 'series',\n",
       " 'link',\n",
       " 'conduct',\n",
       " 'notion',\n",
       " 'series',\n",
       " 'series',\n",
       " 'link',\n",
       " 'design',\n",
       " 'series',\n",
       " 'design',\n",
       " 'version',\n",
       " 'obvious',\n",
       " 'lecture',\n",
       " 'version',\n",
       " 'dramatic',\n",
       " 'extract',\n",
       " 'extract',\n",
       " 'extract',\n",
       " 'extract',\n",
       " 'series',\n",
       " 'extract',\n",
       " 'contrast',\n",
       " 'obvious',\n",
       " 'dramatic',\n",
       " 'extract',\n",
       " 'physical',\n",
       " 'obvious',\n",
       " 'adaptation',\n",
       " 'link',\n",
       " 'extract',\n",
       " 'theme',\n",
       " 'extract',\n",
       " 'image',\n",
       " 'project',\n",
       " 'image',\n",
       " 'image',\n",
       " 'image',\n",
       " 'mode',\n",
       " 'mode',\n",
       " 'hence',\n",
       " 'instance',\n",
       " 'design',\n",
       " 'controversy',\n",
       " 'controversy',\n",
       " 'controversy',\n",
       " 'lecture',\n",
       " 'contrast',\n",
       " 'cycle',\n",
       " 'cultural',\n",
       " 'contrast',\n",
       " 'contrast',\n",
       " 'location',\n",
       " 'emphasis',\n",
       " 'text',\n",
       " 'reaction',\n",
       " 'impact',\n",
       " 'odd',\n",
       " 'demonstrate',\n",
       " 'focus',\n",
       " 'emphasis',\n",
       " 'image',\n",
       " 'contrast',\n",
       " 'contrast',\n",
       " 'resolution',\n",
       " 'displacement',\n",
       " 'enormous',\n",
       " 'trace',\n",
       " 'theme',\n",
       " 'theme',\n",
       " 'contrast',\n",
       " 'cycle',\n",
       " 'displacement',\n",
       " 'explicit',\n",
       " 'explicit',\n",
       " 'emphasis',\n",
       " 'constant',\n",
       " 'emphasis',\n",
       " 'code',\n",
       " 'image',\n",
       " 'link',\n",
       " 'couple',\n",
       " 'contemporary',\n",
       " 'consumer',\n",
       " 'consumer',\n",
       " 'consumer',\n",
       " 'community',\n",
       " 'community',\n",
       " 'community',\n",
       " 'community',\n",
       " 'consumer',\n",
       " 'consumer',\n",
       " 'image',\n",
       " 'link',\n",
       " 'consumer',\n",
       " 'consumer',\n",
       " 'professional',\n",
       " 'couple',\n",
       " 'consumer',\n",
       " 'image',\n",
       " 'whereas']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aca_words_per_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f03b040-9087-43a2-9aaf-174febca5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_aca_list(palabras):\n",
    "    number_aca = []\n",
    "    for palabra in palabras:\n",
    "        number_aca+=[pair[0] for pair in palabra]\n",
    "    return len(number_aca), len(number_aca)/len(tokens)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0fc7859-2c71-425a-9ef4-01993cd1dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(4, 0.005951229672831149)\n",
      "(12, 0.01785368901849345)\n",
      "(14, 0.020829303854909022)\n",
      "(5, 0.007439037091038936)\n",
      "(5, 0.007439037091038936)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(6, 0.008926844509246724)\n",
      "(7, 0.010414651927454511)\n",
      "(6, 0.008926844509246724)\n",
      "(6, 0.008926844509246724)\n",
      "(11, 0.016365881600285657)\n",
      "(7, 0.010414651927454511)\n",
      "(15, 0.022317111273116808)\n",
      "(6, 0.008926844509246724)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(8, 0.011902459345662298)\n",
      "(8, 0.011902459345662298)\n",
      "(8, 0.011902459345662298)\n",
      "(9, 0.013390266763870085)\n",
      "(4, 0.005951229672831149)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(10, 0.014878074182077872)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(6, 0.008926844509246724)\n",
      "(4, 0.005951229672831149)\n",
      "(9, 0.013390266763870085)\n",
      "(9, 0.013390266763870085)\n",
      "(3, 0.004463422254623362)\n",
      "(5, 0.007439037091038936)\n",
      "(11, 0.016365881600285657)\n",
      "(4, 0.005951229672831149)\n",
      "(9, 0.013390266763870085)\n",
      "(4, 0.005951229672831149)\n",
      "(8, 0.011902459345662298)\n",
      "(9, 0.013390266763870085)\n",
      "(10, 0.014878074182077872)\n",
      "(8, 0.011902459345662298)\n",
      "(12, 0.01785368901849345)\n",
      "(13, 0.019341496436701234)\n",
      "(12, 0.01785368901849345)\n",
      "(10, 0.014878074182077872)\n",
      "(12, 0.01785368901849345)\n",
      "(8, 0.011902459345662298)\n",
      "(6, 0.008926844509246724)\n",
      "(10, 0.014878074182077872)\n",
      "(4, 0.005951229672831149)\n",
      "(7, 0.010414651927454511)\n",
      "(8, 0.011902459345662298)\n",
      "(4, 0.005951229672831149)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(7, 0.010414651927454511)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(9, 0.013390266763870085)\n",
      "(8, 0.011902459345662298)\n",
      "(8, 0.011902459345662298)\n",
      "(6, 0.008926844509246724)\n",
      "(10, 0.014878074182077872)\n",
      "(6, 0.008926844509246724)\n",
      "(7, 0.010414651927454511)\n",
      "(9, 0.013390266763870085)\n",
      "(15, 0.022317111273116808)\n",
      "(8, 0.011902459345662298)\n",
      "(9, 0.013390266763870085)\n",
      "(8, 0.011902459345662298)\n",
      "(9, 0.013390266763870085)\n",
      "(12, 0.01785368901849345)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(8, 0.011902459345662298)\n",
      "(6, 0.008926844509246724)\n",
      "(11, 0.016365881600285657)\n",
      "(8, 0.011902459345662298)\n",
      "(9, 0.013390266763870085)\n",
      "(5, 0.007439037091038936)\n",
      "(7, 0.010414651927454511)\n",
      "(5, 0.007439037091038936)\n",
      "(4, 0.005951229672831149)\n",
      "(12, 0.01785368901849345)\n",
      "(7, 0.010414651927454511)\n",
      "(4, 0.005951229672831149)\n",
      "(5, 0.007439037091038936)\n",
      "(5, 0.007439037091038936)\n",
      "(7, 0.010414651927454511)\n",
      "(5, 0.007439037091038936)\n",
      "(10, 0.014878074182077872)\n",
      "(5, 0.007439037091038936)\n",
      "(9, 0.013390266763870085)\n",
      "(5, 0.007439037091038936)\n",
      "(14, 0.020829303854909022)\n",
      "(10, 0.014878074182077872)\n",
      "(6, 0.008926844509246724)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(8, 0.011902459345662298)\n",
      "(8, 0.011902459345662298)\n",
      "(9, 0.013390266763870085)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(5, 0.007439037091038936)\n",
      "(7, 0.010414651927454511)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(8, 0.011902459345662298)\n",
      "(10, 0.014878074182077872)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(8, 0.011902459345662298)\n",
      "(8, 0.011902459345662298)\n",
      "(7, 0.010414651927454511)\n",
      "(10, 0.014878074182077872)\n",
      "(8, 0.011902459345662298)\n",
      "(11, 0.016365881600285657)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(9, 0.013390266763870085)\n",
      "(9, 0.013390266763870085)\n",
      "(8, 0.011902459345662298)\n",
      "(10, 0.014878074182077872)\n",
      "(4, 0.005951229672831149)\n",
      "(4, 0.005951229672831149)\n",
      "(8, 0.011902459345662298)\n",
      "(7, 0.010414651927454511)\n",
      "(6, 0.008926844509246724)\n",
      "(10, 0.014878074182077872)\n",
      "(6, 0.008926844509246724)\n",
      "(10, 0.014878074182077872)\n",
      "(6, 0.008926844509246724)\n",
      "(6, 0.008926844509246724)\n",
      "(12, 0.01785368901849345)\n",
      "(10, 0.014878074182077872)\n",
      "(11, 0.016365881600285657)\n",
      "(12, 0.01785368901849345)\n",
      "(8, 0.011902459345662298)\n",
      "(7, 0.010414651927454511)\n",
      "(12, 0.01785368901849345)\n",
      "(12, 0.01785368901849345)\n",
      "(7, 0.010414651927454511)\n",
      "(12, 0.01785368901849345)\n",
      "(12, 0.01785368901849345)\n",
      "(6, 0.008926844509246724)\n",
      "(14, 0.020829303854909022)\n",
      "(7, 0.010414651927454511)\n",
      "(7, 0.010414651927454511)\n",
      "(9, 0.013390266763870085)\n",
      "(10, 0.014878074182077872)\n",
      "(7, 0.010414651927454511)\n",
      "(10, 0.014878074182077872)\n",
      "(9, 0.013390266763870085)\n",
      "(7, 0.010414651927454511)\n",
      "(3, 0.004463422254623362)\n",
      "(7, 0.010414651927454511)\n",
      "(11, 0.016365881600285657)\n",
      "(6, 0.008926844509246724)\n",
      "(4, 0.005951229672831149)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(10, 0.014878074182077872)\n",
      "(11, 0.016365881600285657)\n",
      "(5, 0.007439037091038936)\n",
      "(7, 0.010414651927454511)\n",
      "(3, 0.004463422254623362)\n",
      "(11, 0.016365881600285657)\n",
      "(6, 0.008926844509246724)\n",
      "(11, 0.016365881600285657)\n",
      "(11, 0.016365881600285657)\n",
      "(6, 0.008926844509246724)\n",
      "(7, 0.010414651927454511)\n",
      "(6, 0.008926844509246724)\n",
      "(11, 0.016365881600285657)\n",
      "(9, 0.013390266763870085)\n",
      "(9, 0.013390266763870085)\n",
      "(9, 0.013390266763870085)\n",
      "(6, 0.008926844509246724)\n",
      "(11, 0.016365881600285657)\n",
      "(6, 0.008926844509246724)\n",
      "(12, 0.01785368901849345)\n",
      "(9, 0.013390266763870085)\n",
      "(10, 0.014878074182077872)\n"
     ]
    }
   ],
   "source": [
    "for palabras in aca_words:\n",
    "    print(number_aca_list(palabras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd208b3-7859-491a-8185-d3ca0e955fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
