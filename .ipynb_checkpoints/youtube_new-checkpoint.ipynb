{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f493dc2",
   "metadata": {},
   "source": [
    "# Corpus YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30461b31",
   "metadata": {},
   "source": [
    "## 1. Lectura de datos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc98573f-6644-4c5a-9a08-66dbbe12e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## abrimos los archivos\n",
    "\n",
    "import glob\n",
    "\n",
    "lista_files = glob.glob('youtube/*.txt')\n",
    "corpus = []\n",
    "\n",
    "for file in lista_files:\n",
    "    with open(file, 'r', encoding='utf8') as f:\n",
    "        corpus+=[f.read()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15522d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## número de textos\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04e0950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(\"Faceshopping\" by Sophie)\\n♪ My face is the front of shop ♪\\n♪ My face is the real shop front ♪\\n♪ My shop is the face I front ♪\\n♪ I\\'m real when I shop my face ♪\\n♪ Artificial bloom ♪\\n♪ Hydroponic skin ♪\\n♪ Chemical release ♪\\n♪ Synthesize the real ♪\\n(upb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81bbb9",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9dd9bf-b5ef-4505-8c67-ad3b187aea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## librerias\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "from nltk import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2fce56-63cb-495b-aaf8-fa7feae6b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jxver\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20361ab2-6bda-46f4-b9bb-561d725c68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## función para remover () y []\n",
    "\n",
    "def a(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14780019-9aa6-4c52-a49a-c526220df1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## aplicamos la función \"a\" a cada texto del corpus\n",
    "\n",
    "corpus = [a(c) for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0b97ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n♪ My face is the front of shop ♪\\n♪ My face is the real shop front ♪\\n♪ My shop is the face I front ♪\\n♪ I'm real when I shop my face ♪\\n♪ Artificial bloom ♪\\n♪ Hydroponic skin ♪\\n♪ Chemical release ♪\\n♪ Synthesize the real ♪\\n - Hey guys, it's Natalie,\\nwel\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ae884b-c67b-4443-b710-6b0f085cb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dividimos por salto de linea cada texto\n",
    "\n",
    "corpus = [c.replace('♪','').split('\\n') for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c624d8-96bd-449d-8378-ec716a91a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' My face is the front of shop ',\n",
       " ' My face is the real shop front ',\n",
       " ' My shop is the face I front ',\n",
       " \" I'm real when I shop my face \"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac550f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## eliminamos strings vacíos (cada texto)\n",
    "\n",
    "corpus = [[sentence.strip() for sentence in c if len(sentence)>0] for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6004d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## volvemos a juntar las oraciones :)\n",
    "\n",
    "corpus = [' '.join(c) for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d62326-be95-4b3d-817f-a1bfbe6bc0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My face is the front of shop My face is the real shop front My shop is the face I front I'm real when I shop my face Artificial bloom Hydroponic skin Chemical release Synthesize the real - Hey guys, it's Natalie, welcome back to my channel. Today I'm\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f16613-b9c2-4ec3-9a90-b9097145f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dividimos en oraciones cada texto\n",
    "\n",
    "sentence_list = []\n",
    "\n",
    "for texto in corpus:\n",
    "    sentences = sent_tokenize(texto)\n",
    "    sentence_list+=[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "964d84c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba60933-2a54-4a8d-9400-618c95b1cd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"My face is the front of shop My face is the real shop front My shop is the face I front I'm real when I shop my face Artificial bloom Hydroponic skin Chemical release Synthesize the real - Hey guys, it's Natalie, welcome back to my channel.\",\n",
       " \"Today I'm gonna do a makeup tutorial, as always, but first, story time, story time, story time!\",\n",
       " \"I just wanna be upfront with you guys and let you know that I've had some facial surgery.\",\n",
       " \"I'm always gonna be honest with you guys about this kind of thing because you mean so much to me.\",\n",
       " \"Like you've been here with me since the beginning, and you've seen my story, my whole entire journey, this journey I've been on as a transgender woman.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c86e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtramos por textos con al menos 2 oraciones\n",
    "\n",
    "sentence_list = [s for s in sentence_list if len(s)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c12d5088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cab91a6-580d-477e-9af2-f5a533a787f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numero de oraciones por texto\n",
    "\n",
    "numero_oraciones = sum([len(s) for s in sentence_list])\n",
    "promedio_oraciones_por_texto = np.mean([len(s) for s in sentence_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fe5fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7355, 319.7826086956522)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numero_oraciones, promedio_oraciones_por_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b513cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokens y types\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for texto in sentence_list:\n",
    "    for sentence in texto:\n",
    "        tokens+=sentence.split(' ')\n",
    "\n",
    "tokens = [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee0ee92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142029, 17593)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## número de tokens y types en el corpus\n",
    "\n",
    "len(tokens),len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "686584ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[322, 1041, 915, 73, 170, 128, 259, 264, 170, 333, 272, 367, 369, 424, 310, 425, 222, 317, 173, 318, 122, 201, 160]\n"
     ]
    }
   ],
   "source": [
    "# número de oraciones por texto\n",
    "num_sen = [len(s) for s in sentence_list]\n",
    "print(num_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85bc9c",
   "metadata": {},
   "source": [
    "## análisis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f2d03",
   "metadata": {},
   "source": [
    "### 1. Nominalizaciones\n",
    "El trabajo aquí es con listas de oraciones. Extraemos los sustantivos :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8870d8c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\jxver\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (3.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (59.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (59.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jxver\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "248d1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "oraciones_nlp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4563f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## identificamos el lema y el pos\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for sentence_text in sentence_list:\n",
    "    if len(sentence_text)>1:\n",
    "        sent = []\n",
    "        for sentence in sentence_text:\n",
    "            doc = nlp(sentence)\n",
    "            sent += [(token.lemma_.lower(),token.pos_) for token in doc]\n",
    "        oraciones_nlp += [sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "131ef0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oraciones_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1c211ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_tokens_types(oraciones):\n",
    "    number = []\n",
    "    for oracion in oraciones:\n",
    "        number+=[pair[0] for pair in oracion]\n",
    "    return len(number),len(set(number)), len(set(number))/len(number)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31835204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12896, 50, 0.38771712158808935)\n",
      "(41748, 54, 0.12934751365334868)\n",
      "(33686, 58, 0.17217835302499554)\n",
      "(4178, 37, 0.8855911919578746)\n",
      "(5996, 40, 0.66711140760507)\n",
      "(5584, 45, 0.8058739255014327)\n",
      "(16434, 53, 0.32250212973104536)\n",
      "(14542, 52, 0.35758492642002476)\n",
      "(7046, 45, 0.6386602327561737)\n",
      "(12976, 50, 0.38532675709001235)\n",
      "(10482, 48, 0.45792787635947335)\n",
      "(17190, 53, 0.30831878999418266)\n",
      "(17298, 43, 0.2485836512891664)\n",
      "(16592, 48, 0.28929604628736744)\n",
      "(15038, 52, 0.3457906636520814)\n",
      "(21308, 55, 0.25811901633189416)\n",
      "(13278, 54, 0.4066877541798464)\n",
      "(19410, 56, 0.28851107676455434)\n",
      "(6412, 50, 0.7797878976918279)\n",
      "(16012, 50, 0.31226580064951287)\n",
      "(8882, 47, 0.5291600990767845)\n",
      "(9894, 56, 0.5659995957145745)\n",
      "(7132, 48, 0.6730229949523275)\n"
     ]
    }
   ],
   "source": [
    "## número de tokens y types para los 23 textos \n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    print(number_tokens_types(oraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41bec5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_nouns(oraciones):\n",
    "    number = [pair for pair in oraciones if pair[1]=='NOUN']\n",
    "    return len(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0661b24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "2832\n",
      "2727\n",
      "320\n",
      "381\n",
      "383\n",
      "1282\n",
      "1077\n",
      "433\n",
      "956\n",
      "804\n",
      "1283\n",
      "1375\n",
      "1469\n",
      "1511\n",
      "1711\n",
      "1075\n",
      "1522\n",
      "508\n",
      "947\n",
      "627\n",
      "573\n",
      "478\n"
     ]
    }
   ],
   "source": [
    "## número de nouns tokens para los 23 textos \n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    print(number_nouns(oraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2bdafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## la pregunta es: ¿De este número de nouns cuántos son nominalizaciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3894534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reglas de nominalization\n",
    "\n",
    "## reglas de nominalization\n",
    "## puse las palabras lematizadas, en ese caso, solo es necesario poner las palabras en singular\n",
    "\n",
    "no_nom = ['thing', 'things', 'somethings', 'something', 'anything', 'everything', 'nothing','original', 'special', 'normal', 'version', 'tutorial', 'moment', 'comment', 'criminal', 'morning', 'tradition', 'notification','question', 'element', 'quality']\n",
    "terminacion = ['ment','ments','tions', 'tion','sions', 'sion', 'ibility','ibilities', 'ity','ities', 'ness','nesses', 'al','als','ings', 'ing'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87126c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nominalization(oraciones):\n",
    "    nom = []\n",
    "    for pair in oraciones:\n",
    "        if pair[0] not in no_nom:\n",
    "            if pair[1]=='NOUN':\n",
    "                for END in terminacion:\n",
    "                    if pair[0].endswith(END):\n",
    "                        nom+=[pair[0]]\n",
    "    return nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "000c1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_list = []\n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    nom_list += [nominalization(oraciones)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32401ff0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beginning',\n",
       " 'feminization',\n",
       " 'feminization',\n",
       " 'contouring',\n",
       " 'contouring',\n",
       " 'incision',\n",
       " 'fragment',\n",
       " 'incision',\n",
       " 'reconstruction',\n",
       " 'incision',\n",
       " 'anticipation',\n",
       " 'encouragement',\n",
       " 'jackal',\n",
       " 'vanity',\n",
       " 'feminization',\n",
       " 'reassignment',\n",
       " 'identity',\n",
       " 'argument',\n",
       " 'reality',\n",
       " 'ideal',\n",
       " 'transition',\n",
       " 'removal',\n",
       " 'grooming',\n",
       " 'thinking',\n",
       " 'realness',\n",
       " 'painting',\n",
       " 'femininity',\n",
       " 'aspiration',\n",
       " 'aging',\n",
       " 'intensity',\n",
       " 'artificial',\n",
       " 'skinmaxing',\n",
       " 'business',\n",
       " 'discussion',\n",
       " 'masculinization',\n",
       " 'looksmaxing',\n",
       " 'deal',\n",
       " 'arousal',\n",
       " 'evolution',\n",
       " 'contouring',\n",
       " 'ingenuity',\n",
       " 'resourcefulness',\n",
       " 'individuality',\n",
       " 'femininity',\n",
       " 'exploitation',\n",
       " 'bartering',\n",
       " 'judgment',\n",
       " 'exaggeration',\n",
       " 'delusion',\n",
       " 'embellishment',\n",
       " 'darkness',\n",
       " 'invention',\n",
       " 'darkness',\n",
       " 'aging',\n",
       " 'ritual',\n",
       " 'cleansing',\n",
       " 'corporation',\n",
       " 'kindness',\n",
       " 'saving',\n",
       " 'collection',\n",
       " 'facial',\n",
       " 'futility',\n",
       " 'solution',\n",
       " 'spiral',\n",
       " 'obsession',\n",
       " 'advertising',\n",
       " 'relation',\n",
       " 'awareness',\n",
       " 'contemplation',\n",
       " 'revolution',\n",
       " 'revolution',\n",
       " 'revolution',\n",
       " 'futility',\n",
       " 'representation',\n",
       " 'celebrity',\n",
       " 'spiral',\n",
       " 'ideal',\n",
       " 'originality',\n",
       " 'appreciation',\n",
       " 'superiority',\n",
       " 'solution',\n",
       " 'audacity',\n",
       " 'kindness']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9b57f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nom_list = []\n",
    "\n",
    "for oraciones in oraciones_nlp:\n",
    "    num_nom_list += [len(nominalization(oraciones)), len(nominalization(oraciones))/number_nouns(oraciones)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c706d5a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83,\n",
       " 8.050436469447138,\n",
       " 366,\n",
       " 12.923728813559322,\n",
       " 326,\n",
       " 11.954528786211954,\n",
       " 38,\n",
       " 11.875,\n",
       " 34,\n",
       " 8.923884514435695,\n",
       " 26,\n",
       " 6.7885117493472595,\n",
       " 148,\n",
       " 11.54446177847114,\n",
       " 83,\n",
       " 7.706592386258125,\n",
       " 37,\n",
       " 8.545034642032332,\n",
       " 113,\n",
       " 11.820083682008368,\n",
       " 76,\n",
       " 9.45273631840796,\n",
       " 131,\n",
       " 10.210444271239282,\n",
       " 135,\n",
       " 9.818181818181818,\n",
       " 234,\n",
       " 15.929203539823009,\n",
       " 250,\n",
       " 16.545334215751158,\n",
       " 168,\n",
       " 9.818819403857393,\n",
       " 96,\n",
       " 8.930232558139535,\n",
       " 126,\n",
       " 8.278580814717477,\n",
       " 62,\n",
       " 12.204724409448819,\n",
       " 102,\n",
       " 10.770855332629356,\n",
       " 83,\n",
       " 13.237639553429027,\n",
       " 75,\n",
       " 13.089005235602095,\n",
       " 40,\n",
       " 8.368200836820083]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## porcentaje de nominalizaciones con respecto al total de tokens sustantivos para cada texto\n",
    "\n",
    "num_nom_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e0540-21b6-4dd0-b89a-6dc6f4e44440",
   "metadata": {},
   "source": [
    "## 2. Academic World List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39a37341-2f7c-443e-af51-ddb1df93dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abriendo la lista de palabras academicas\n",
    "with open('AcademicWordList.txt') as f:\n",
    "    AWL=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d44543b-6da2-4619-b912-34c81138a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir por salto de linea\n",
    "AWL= AWL.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e10d07b4-34e8-4325-997d-bef3e20a069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##eliminar espacios en blanco\n",
    "AWL = [palabra.split(' ') for palabra in AWL if len(palabra)>0]\n",
    "AWL = [item for sublist in AWL for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ffcef50-7f60-4c4f-a094-b63321bcda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWL.remove('-')\n",
    "AWL.remove('comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "99c5dda9-db65-4030-ad1a-0d44525e63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = list(zip(*oraciones_nlp[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dcc0dcd2-0dbd-4776-957b-cec6dc04023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my', 'face', 'be', 'the', 'front', 'of', 'shop', 'my', 'face', 'be')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b31d8f3-d68f-4288-9788-56e877038e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142029"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd98ad-174c-4b9e-9e23-35ce5d7ed1c8",
   "metadata": {},
   "source": [
    "# PROBLEMAS AQUÍ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac27ab8b-196b-4433-a840-d2a75441591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def academic(tokens):\n",
    "    aca_list=[]\n",
    "    for word in tokens:\n",
    "        if word in AWL:\n",
    "            aca_list+=[word]\n",
    "    return aca_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "629534ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my', 'PRON'),\n",
       " ('face', 'NOUN'),\n",
       " ('be', 'AUX'),\n",
       " ('the', 'DET'),\n",
       " ('front', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('shop', 'NOUN'),\n",
       " ('my', 'PRON'),\n",
       " ('face', 'NOUN'),\n",
       " ('be', 'AUX')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oraciones_nlp[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ff7b5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = list(zip(*oracion))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e2718b1-9efe-42bc-9ad6-7d8ff9c463ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "aca_words_percentage = []\n",
    "\n",
    "aca_words_per_text = []\n",
    "\n",
    "for oracion in oraciones_nlp:\n",
    "        texto = list(zip(*oracion))[0]\n",
    "        aca_words = academic(texto)\n",
    "        aca_words_per_text+=[aca_words]\n",
    "        aca_words_percentage += [len(aca_words)/len(texto)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3342c095-142a-4ab3-a371-139ee3b77b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.163151364764268,\n",
       " 1.1497556769186548,\n",
       " 1.4605474084189278,\n",
       " 1.8669219722355195,\n",
       " 0.5670446964643095,\n",
       " 0.5372492836676217,\n",
       " 0.9492515516611902,\n",
       " 1.0314949800577637,\n",
       " 2.7249503264263413,\n",
       " 1.155980271270037,\n",
       " 1.2020606754436176,\n",
       " 1.1634671320535195,\n",
       " 1.1793270898369754,\n",
       " 2.941176470588235,\n",
       " 2.3673360819257883,\n",
       " 2.1869720292847754,\n",
       " 1.6418135261334537,\n",
       " 1.4940752189592994,\n",
       " 2.2145976294447913,\n",
       " 0.7869098176367724,\n",
       " 0.990767845079937,\n",
       " 1.1926420052557105,\n",
       " 1.0936623667975323]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aca_words_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df34e9de-45e1-4a0b-9306-81b6c6cff8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_aca_list(palabras):\n",
    "    number_aca = []\n",
    "    for palabra in palabras:\n",
    "        number_aca+=[pair[0] for pair in palabra]\n",
    "    return len(number_aca), len(number_aca)/len(tokens)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7d7796d-0ba6-4be8-b681-8d24ad7462de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12896, 9.07983580818002)\n",
      "(41748, 29.393997000612547)\n",
      "(33686, 23.71769145737842)\n",
      "(4178, 2.941652761055841)\n",
      "(5996, 4.221673038604791)\n",
      "(5584, 3.931591435551894)\n",
      "(16434, 11.570876370318738)\n",
      "(14542, 10.238754057269993)\n",
      "(7046, 4.960958677453196)\n",
      "(12976, 9.13616233304466)\n",
      "(10482, 7.380182920389498)\n",
      "(17190, 12.103162030289589)\n",
      "(17298, 12.179202838856854)\n",
      "(16592, 11.682121256926402)\n",
      "(15038, 10.587978511430764)\n",
      "(21308, 15.002569897696949)\n",
      "(13278, 9.348794964408677)\n",
      "(19410, 13.666223095283359)\n",
      "(6412, 4.514570967900921)\n",
      "(16012, 11.27375395165776)\n",
      "(8882, 6.253652423096691)\n",
      "(9894, 6.966182962634392)\n",
      "(7132, 5.0215096916826845)\n"
     ]
    }
   ],
   "source": [
    "for oraciones in oraciones_nlp:\n",
    "    print(number_aca_list(oraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e3beb-c8d5-4e20-8c17-e5c53ca7da44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
